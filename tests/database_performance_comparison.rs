use anyhow::Result;
use std::path::PathBuf;
use std::sync::Arc;
use std::time::{Duration, Instant, SystemTime};
use tempfile::TempDir;

use vuio::database::{
    DatabaseManager, MediaFile, SqliteDatabase,
    zerocopy::{ZeroCopyDatabase, ZeroCopyConfig},
};

/// Performance metrics for database operations
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    pub operation: String,
    pub duration: Duration,
    pub throughput_ops_per_sec: f64,
    pub memory_usage_mb: f64,
    pub cpu_usage_percent: f64,
    pub files_processed: usize,
}

/// Comprehensive performance test suite comparing SQL vs ZeroCopy databases
pub struct DatabasePerformanceComparison {
    temp_dir: TempDir,
    sql_db: Arc<SqliteDatabase>,
    test_files: Vec<MediaFile>,
}

/// ZeroCopy database configuration profiles for performance testing
#[derive(Debug, Clone)]
pub struct ZeroCopyProfile {
    pub name: String,
    pub config: ZeroCopyConfig,
}

impl ZeroCopyProfile {
    /// Minimal configuration (default)
    pub fn minimal() -> Self {
        Self {
            name: "Minimal (1MB cache, 1K index, 100 batch)".to_string(),
            config: ZeroCopyConfig::default(),
        }
    }
    
    /// Small configuration (4MB RAM usage - optimized for index and batch)
    pub fn small() -> Self {
        Self {
            name: "Small (4MB RAM: 2M index, 100K batch)".to_string(),
            config: ZeroCopyConfig {
                memory_map_size_mb: 4,                              // Small cache
                index_cache_size: 2_000_000,                        // 2M entries for better performance
                batch_size: 100_000,                                // Large batches for efficiency
                initial_file_size_mb: 100,                          // Larger initial file
                max_file_size_gb: 20,                               // Allow growth
                sync_frequency: Duration::from_secs(30),            // More frequent sync
                enable_wal: true,                                   // Enable WAL for performance
                performance_monitoring_interval: Duration::from_secs(180),
                ..Default::default()
            },
        }
    }
    
    /// Medium configuration (128MB RAM usage - aggressive index and batch)
    pub fn medium() -> Self {
        Self {
            name: "Medium (128MB RAM: 6M index, 300K batch)".to_string(),
            config: ZeroCopyConfig {
                memory_map_size_mb: 32,                             // Moderate cache
                index_cache_size: 6_000_000,                        // 6M entries for high performance
                batch_size: 300_000,                                // Very large batches
                initial_file_size_mb: 200,                          // Large initial file
                max_file_size_gb: 50,                               // Allow significant growth
                sync_frequency: Duration::from_secs(15),            // Frequent sync
                enable_wal: true,                                   // Enable WAL
                enable_compression: false,                          // Keep disabled for speed
                performance_monitoring_interval: Duration::from_secs(120),
                ..Default::default()
            },
        }
    }
    
    /// Large configuration (256MB RAM usage - maximum index and batch)
    pub fn large() -> Self {
        Self {
            name: "Large (256MB RAM: 8M index, 500K batch)".to_string(),
            config: ZeroCopyConfig {
                memory_map_size_mb: 64,                             // Large cache
                index_cache_size: 8_000_000,                        // 8M entries for excellent performance
                batch_size: 500_000,                                // Massive batches
                initial_file_size_mb: 300,                          // Large initial file
                max_file_size_gb: 75,                               // Large growth capacity
                sync_frequency: Duration::from_secs(10),            // Very frequent sync
                enable_wal: true,                                   // Enable WAL
                enable_compression: false,                          // Disabled for maximum speed
                performance_monitoring_interval: Duration::from_secs(60),
                ..Default::default()
            },
        }
    }
    
    /// Extreme configuration (1GB RAM usage - absolute maximum)
    pub fn extreme() -> Self {
        Self {
            name: "Extreme (1GB RAM: 10M index, 1M batch)".to_string(),
            config: ZeroCopyConfig {
                memory_map_size_mb: 512,                            // Maximum cache for memory mapping
                index_cache_size: 10_000_000,                       // Maximum index entries
                batch_size: 1_000_000,                              // Maximum batch size
                initial_file_size_mb: 1000,                         // Very large initial file (1GB)
                max_file_size_gb: 100,                              // Maximum growth
                sync_frequency: Duration::from_secs(5),             // Extremely frequent sync
                enable_wal: true,                                   // Enable WAL
                enable_compression: false,                          // Disabled for absolute speed
                performance_monitoring_interval: Duration::from_secs(30),
                ..Default::default()
            },
        }
    }
}

impl DatabasePerformanceComparison {
    /// Initialize the performance comparison test suite
    pub async fn new() -> Result<Self> {
        let temp_dir = TempDir::new()?;
        
        // Initialize SQL database
        let sql_db_path = temp_dir.path().join("test_sql.db");
        let sql_db = Arc::new(SqliteDatabase::new(sql_db_path).await?);
        sql_db.initialize().await?;
        
        // Generate test data - more files for comprehensive testing
        let test_files = Self::generate_test_media_files(5000);
        
        Ok(Self {
            temp_dir,
            sql_db,
            test_files,
        })
    }
    
    /// Create a ZeroCopy database with the specified profile
    async fn create_zerocopy_db(&self, profile: &ZeroCopyProfile) -> Result<Arc<ZeroCopyDatabase>> {
        let db_path = self.temp_dir.path().join(format!("zerocopy_{}.db", profile.name.replace(" ", "_").replace("(", "").replace(")", "").replace(",", "")));
        let db = Arc::new(ZeroCopyDatabase::new(db_path, Some(profile.config.clone())).await?);
        db.initialize().await?;
        db.open().await?;
        Ok(db)
    }
    
    /// Generate synthetic media files for testing
    fn generate_test_media_files(count: usize) -> Vec<MediaFile> {
        let mut files = Vec::with_capacity(count);
        let base_path = PathBuf::from("/test/media");
        
        for i in 0..count {
            let file_path = base_path.join(format!("track_{:06}.mp3", i));
            let mut file = MediaFile::new(
                file_path,
                fastrand::u64(1_000_000..100_000_000), // 1MB to 100MB
                "audio/mpeg".to_string(),
            );
            
            // Add metadata
            file.title = Some(format!("Track {}", i));
            file.artist = Some(format!("Artist {}", i % 100)); // 100 different artists
            file.album = Some(format!("Album {}", i % 50));     // 50 different albums
            file.genre = Some(Self::random_genre());
            file.track_number = Some((i % 20) as u32 + 1);     // 1-20 tracks per album
            file.year = Some(2000 + (i % 24) as u32);          // Years 2000-2023
            file.album_artist = file.artist.clone();
            file.duration = Some(Duration::from_secs(fastrand::u64(120..600))); // 2-10 minutes
            
            files.push(file);
        }
        
        files
    }
    
    /// Get a random music genre for test data
    fn random_genre() -> String {
        let genres = [
            "Rock", "Pop", "Jazz", "Classical", "Electronic", "Hip-Hop",
            "Country", "Blues", "Folk", "Reggae", "Metal", "Punk",
            "Alternative", "Indie", "R&B", "Soul", "Funk", "Disco",
        ];
        genres[fastrand::usize(0..genres.len())].to_string()
    }
    
    /// Measure memory usage (simplified estimation)
    fn measure_memory_usage() -> f64 {
        // In a real implementation, you'd use system APIs to get actual memory usage
        // For this test, we'll return a placeholder value
        0.0
    }
    
    /// Measure CPU usage (simplified estimation)
    fn measure_cpu_usage() -> f64 {
        // In a real implementation, you'd measure actual CPU usage
        // For this test, we'll return a placeholder value
        0.0
    }
    
    /// Create a fresh SQL database for testing
    async fn create_sql_db(&self, test_name: &str) -> Result<Arc<SqliteDatabase>> {
        let sql_db_path = self.temp_dir.path().join(format!("test_sql_{}.db", test_name.replace(" ", "_").replace("(", "").replace(")", "").replace(",", "")));
        let sql_db = Arc::new(SqliteDatabase::new(sql_db_path).await?);
        sql_db.initialize().await?;
        Ok(sql_db)
    }
    
    /// Run bulk insert performance test with a specific ZeroCopy profile
    pub async fn test_bulk_insert_with_profile(&self, profile: &ZeroCopyProfile) -> Result<(PerformanceMetrics, PerformanceMetrics)> {
        println!("🚀 Running bulk insert test: {}", profile.name);
        
        // Create fresh SQL database for this test to avoid conflicts
        let sql_db = self.create_sql_db(&profile.name).await?;
        
        // Test SQL database
        let start_time = Instant::now();
        let start_memory = Self::measure_memory_usage();
        let start_cpu = Self::measure_cpu_usage();
        
        let sql_ids = sql_db.bulk_store_media_files(&self.test_files).await?;
        
        let sql_duration = start_time.elapsed();
        let sql_throughput = self.test_files.len() as f64 / sql_duration.as_secs_f64();
        let sql_metrics = PerformanceMetrics {
            operation: format!("SQL Bulk Insert (vs {})", profile.name),
            duration: sql_duration,
            throughput_ops_per_sec: sql_throughput,
            memory_usage_mb: Self::measure_memory_usage() - start_memory,
            cpu_usage_percent: Self::measure_cpu_usage() - start_cpu,
            files_processed: sql_ids.len(),
        };
        
        // Test ZeroCopy database with specific profile
        let zerocopy_db = self.create_zerocopy_db(profile).await?;
        
        let start_time = Instant::now();
        let start_memory = Self::measure_memory_usage();
        let start_cpu = Self::measure_cpu_usage();
        
        let zerocopy_ids = zerocopy_db.bulk_store_media_files(&self.test_files).await?;
        
        let zerocopy_duration = start_time.elapsed();
        let zerocopy_throughput = self.test_files.len() as f64 / zerocopy_duration.as_secs_f64();
        let zerocopy_metrics = PerformanceMetrics {
            operation: format!("ZeroCopy Bulk Insert ({})", profile.name),
            duration: zerocopy_duration,
            throughput_ops_per_sec: zerocopy_throughput,
            memory_usage_mb: Self::measure_memory_usage() - start_memory,
            cpu_usage_percent: Self::measure_cpu_usage() - start_cpu,
            files_processed: zerocopy_ids.len(),
        };
        
        println!("   SQL:      {:.0} files/sec ({:.2}ms)", sql_throughput, sql_duration.as_millis());
        println!("   ZeroCopy: {:.0} files/sec ({:.2}ms)", zerocopy_throughput, zerocopy_duration.as_millis());
        
        let improvement = if zerocopy_throughput > sql_throughput {
            format!("ZeroCopy is {:.1}% faster", (zerocopy_throughput / sql_throughput - 1.0) * 100.0)
        } else {
            format!("SQL is {:.1}% faster", (sql_throughput / zerocopy_throughput - 1.0) * 100.0)
        };
        println!("   Result:   {}", improvement);
        
        Ok((sql_metrics, zerocopy_metrics))
    }
    
    /// Run query performance test (deprecated - use individual tests instead)
    pub async fn test_query_performance(&self) -> Result<(PerformanceMetrics, PerformanceMetrics)> {
        println!("🔍 Running query performance test...");
        
        // This method is deprecated in favor of individual profile-based tests
        // Return dummy metrics for compatibility
        let dummy_metrics = PerformanceMetrics {
            operation: "Deprecated".to_string(),
            duration: Duration::from_millis(1),
            throughput_ops_per_sec: 1.0,
            memory_usage_mb: 0.0,
            cpu_usage_percent: 0.0,
            files_processed: 0,
        };
        
        println!("✅ Query performance test completed (deprecated)");
        Ok((dummy_metrics.clone(), dummy_metrics))
    }
    
    /// Run update performance test (deprecated - use individual tests instead)
    pub async fn test_update_performance(&self) -> Result<(PerformanceMetrics, PerformanceMetrics)> {
        println!("📝 Running update performance test...");
        
        // This method is deprecated in favor of individual profile-based tests
        // Return dummy metrics for compatibility
        let dummy_metrics = PerformanceMetrics {
            operation: "Deprecated".to_string(),
            duration: Duration::from_millis(1),
            throughput_ops_per_sec: 1.0,
            memory_usage_mb: 0.0,
            cpu_usage_percent: 0.0,
            files_processed: 0,
        };
        
        println!("✅ Update performance test completed (deprecated)");
        Ok((dummy_metrics.clone(), dummy_metrics))
    }
    
    /// Run streaming performance test (deprecated - use individual tests instead)
    pub async fn test_streaming_performance(&self) -> Result<(PerformanceMetrics, PerformanceMetrics)> {
        println!("🌊 Running streaming performance test...");
        
        // This method is deprecated in favor of individual profile-based tests
        // Return dummy metrics for compatibility
        let dummy_metrics = PerformanceMetrics {
            operation: "Deprecated".to_string(),
            duration: Duration::from_millis(1),
            throughput_ops_per_sec: 1.0,
            memory_usage_mb: 0.0,
            cpu_usage_percent: 0.0,
            files_processed: 0,
        };
        
        println!("✅ Streaming performance test completed (deprecated)");
        Ok((dummy_metrics.clone(), dummy_metrics))
    }
    
    /// Run concurrent access performance test (deprecated - use individual tests instead)
    pub async fn test_concurrent_performance(&self) -> Result<(PerformanceMetrics, PerformanceMetrics)> {
        println!("🔄 Running concurrent access performance test...");
        
        // This method is deprecated in favor of individual profile-based tests
        // Return dummy metrics for compatibility
        let dummy_metrics = PerformanceMetrics {
            operation: "Deprecated".to_string(),
            duration: Duration::from_millis(1),
            throughput_ops_per_sec: 1.0,
            memory_usage_mb: 0.0,
            cpu_usage_percent: 0.0,
            files_processed: 0,
        };
        
        println!("✅ Concurrent access test completed (deprecated)");
        Ok((dummy_metrics.clone(), dummy_metrics))
    }
    
    /// Print performance comparison results
    pub fn print_comparison_results(&self, results: &[(PerformanceMetrics, PerformanceMetrics)]) {
        println!("\n📊 DATABASE PERFORMANCE COMPARISON RESULTS");
        println!("{}", "=".repeat(80));
        
        for (sql_metrics, zerocopy_metrics) in results {
            println!("\n🔬 Test: {}", sql_metrics.operation.replace("SQL ", ""));
            println!("{}", "-".repeat(60));
            
            // Duration comparison
            println!("⏱️  Duration:");
            println!("   SQL:      {:>10.3}ms", sql_metrics.duration.as_millis());
            println!("   ZeroCopy: {:>10.3}ms", zerocopy_metrics.duration.as_millis());
            let duration_improvement = if sql_metrics.duration > zerocopy_metrics.duration {
                let improvement = (sql_metrics.duration.as_secs_f64() / zerocopy_metrics.duration.as_secs_f64() - 1.0) * 100.0;
                format!("ZeroCopy is {:.1}% faster", improvement)
            } else {
                let improvement = (zerocopy_metrics.duration.as_secs_f64() / sql_metrics.duration.as_secs_f64() - 1.0) * 100.0;
                format!("SQL is {:.1}% faster", improvement)
            };
            println!("   Result:   {}", duration_improvement);
            
            // Throughput comparison
            println!("\n🚀 Throughput (ops/sec):");
            println!("   SQL:      {:>10.0}", sql_metrics.throughput_ops_per_sec);
            println!("   ZeroCopy: {:>10.0}", zerocopy_metrics.throughput_ops_per_sec);
            let throughput_improvement = if zerocopy_metrics.throughput_ops_per_sec > sql_metrics.throughput_ops_per_sec {
                let improvement = (zerocopy_metrics.throughput_ops_per_sec / sql_metrics.throughput_ops_per_sec - 1.0) * 100.0;
                format!("ZeroCopy is {:.1}% faster", improvement)
            } else {
                let improvement = (sql_metrics.throughput_ops_per_sec / zerocopy_metrics.throughput_ops_per_sec - 1.0) * 100.0;
                format!("SQL is {:.1}% faster", improvement)
            };
            println!("   Result:   {}", throughput_improvement);
            
            // Files processed
            println!("\n📁 Files Processed:");
            println!("   SQL:      {:>10}", sql_metrics.files_processed);
            println!("   ZeroCopy: {:>10}", zerocopy_metrics.files_processed);
        }
        
        // Overall summary
        println!("\n🏆 OVERALL SUMMARY");
        println!("{}", "=".repeat(80));
        
        let mut sql_wins = 0;
        let mut zerocopy_wins = 0;
        let mut total_sql_time = Duration::new(0, 0);
        let mut total_zerocopy_time = Duration::new(0, 0);
        
        for (sql_metrics, zerocopy_metrics) in results {
            total_sql_time += sql_metrics.duration;
            total_zerocopy_time += zerocopy_metrics.duration;
            
            if sql_metrics.throughput_ops_per_sec > zerocopy_metrics.throughput_ops_per_sec {
                sql_wins += 1;
            } else {
                zerocopy_wins += 1;
            }
        }
        
        println!("Test Results:");
        println!("   SQL wins:      {} tests", sql_wins);
        println!("   ZeroCopy wins: {} tests", zerocopy_wins);
        
        println!("\nTotal Execution Time:");
        println!("   SQL:      {:>10.3}ms", total_sql_time.as_millis());
        println!("   ZeroCopy: {:>10.3}ms", total_zerocopy_time.as_millis());
        
        let overall_improvement = if total_sql_time > total_zerocopy_time {
            let improvement = (total_sql_time.as_secs_f64() / total_zerocopy_time.as_secs_f64() - 1.0) * 100.0;
            format!("ZeroCopy is {:.1}% faster overall", improvement)
        } else {
            let improvement = (total_zerocopy_time.as_secs_f64() / total_sql_time.as_secs_f64() - 1.0) * 100.0;
            format!("SQL is {:.1}% faster overall", improvement)
        };
        println!("   Result:   {}", overall_improvement);
        
        println!("\n💡 RECOMMENDATIONS");
        println!("{}", "=".repeat(80));
        if zerocopy_wins > sql_wins {
            println!("✅ ZeroCopy database shows better performance for this workload");
            println!("   - Consider using ZeroCopy for high-throughput scenarios");
            println!("   - ZeroCopy excels in read-heavy workloads with memory mapping");
            println!("   - Better for scenarios requiring low-latency access");
            println!("   - Minimal resource usage makes it suitable for constrained environments");
        } else {
            println!("✅ SQL database shows better performance for this workload");
            println!("   - SQL provides more consistent performance across operations");
            println!("   - Better for complex queries and transactions");
            println!("   - More mature ecosystem and tooling");
            println!("   - ZeroCopy can be tuned with larger cache sizes for better performance");
        }
        
        println!("\n📈 PERFORMANCE CHARACTERISTICS");
        println!("{}", "=".repeat(80));
        println!("SQL Database:");
        println!("   + Mature, well-tested technology");
        println!("   + ACID compliance and transactions");
        println!("   + Complex query capabilities");
        println!("   + Excellent tooling and debugging");
        println!("   - Higher memory overhead");
        println!("   - Serialization/deserialization costs");
        
        println!("\nZeroCopy Database (Minimal Settings):");
        println!("   + Zero-copy memory access");
        println!("   + Minimal resource usage by default");
        println!("   + FlatBuffer serialization efficiency");
        println!("   + Memory-mapped file performance");
        println!("   + Configurable for different workloads");
        println!("   - More complex implementation");
        println!("   - Limited query flexibility");
        println!("   - Newer, less battle-tested");
    }
    
    /// Run comprehensive performance benchmark across all configurations
    pub async fn run_comprehensive_benchmark(&self) -> Result<()> {
        println!("🎯 COMPREHENSIVE DATABASE PERFORMANCE COMPARISON");
        println!("Test dataset: {} media files", self.test_files.len());
        println!("{}", "=".repeat(80));
        
        let profiles = vec![
            ZeroCopyProfile::minimal(),
            ZeroCopyProfile::small(),
            ZeroCopyProfile::medium(),
            ZeroCopyProfile::large(),
            ZeroCopyProfile::extreme(),
        ];
        
        let mut all_results = Vec::new();
        
        println!("\n📊 BULK INSERT PERFORMANCE COMPARISON");
        println!("{}", "-".repeat(60));
        
        // Test bulk insert performance with each profile
        for profile in &profiles {
            let result = self.test_bulk_insert_with_profile(profile).await?;
            all_results.push(result);
            println!(); // Add spacing between tests
        }
        
        // Print comprehensive summary
        self.print_scaling_analysis(&all_results);
        
        Ok(())
    }
    
    /// Print scaling analysis and recommendations
    pub fn print_scaling_analysis(&self, results: &[(PerformanceMetrics, PerformanceMetrics)]) {
        println!("\n🔍 SCALING ANALYSIS & RECOMMENDATIONS");
        println!("{}", "=".repeat(80));
        
        println!("\n📈 Performance Scaling:");
        println!("{:<40} {:>15} {:>15} {:>15}", "Configuration", "SQL (files/sec)", "ZeroCopy (files/sec)", "Improvement");
        println!("{}", "-".repeat(85));
        
        for (sql_metrics, zerocopy_metrics) in results {
            let improvement = if zerocopy_metrics.throughput_ops_per_sec > sql_metrics.throughput_ops_per_sec {
                format!("+{:.1}%", (zerocopy_metrics.throughput_ops_per_sec / sql_metrics.throughput_ops_per_sec - 1.0) * 100.0)
            } else {
                format!("-{:.1}%", (1.0 - zerocopy_metrics.throughput_ops_per_sec / sql_metrics.throughput_ops_per_sec) * 100.0)
            };
            
            // Extract configuration name from operation string
            let config_name = zerocopy_metrics.operation
                .strip_prefix("ZeroCopy Bulk Insert (")
                .and_then(|s| s.strip_suffix(")"))
                .unwrap_or("Unknown");
            
            println!("{:<40} {:>15.0} {:>15.0} {:>15}", 
                     config_name,
                     sql_metrics.throughput_ops_per_sec,
                     zerocopy_metrics.throughput_ops_per_sec,
                     improvement);
        }
        
        println!("\n💡 CONFIGURATION RECOMMENDATIONS");
        println!("{}", "=".repeat(80));
        
        println!("🔧 Choose your configuration based on your environment:");
        println!();
        
        println!("📱 MINIMAL (1MB cache, 1K index, 100 batch):");
        println!("   ✅ Best for: Embedded systems, IoT devices, containers with <512MB RAM");
        println!("   ✅ Use when: Memory is extremely limited, small media libraries (<10K files)");
        println!("   ⚙️  Environment variables:");
        println!("      ZEROCOPY_CACHE_MB=1");
        println!("      ZEROCOPY_INDEX_SIZE=1000");
        println!("      ZEROCOPY_BATCH_SIZE=100");
        println!();
        
        println!("🖥️  SMALL (4MB cache, 2M index, 100K batch):");
        println!("   ✅ Best for: Small servers, Raspberry Pi 4, containers with 1-2GB RAM");
        println!("   ✅ Use when: Medium media libraries (10K-100K files), good performance");
        println!("   ⚙️  Environment variables:");
        println!("      ZEROCOPY_CACHE_MB=4");
        println!("      ZEROCOPY_INDEX_SIZE=2000000");
        println!("      ZEROCOPY_BATCH_SIZE=100000");
        println!("      ZEROCOPY_ENABLE_WAL=true");
        println!();
        
        println!("🖥️  MEDIUM (32MB cache, 6M index, 300K batch):");
        println!("   ✅ Best for: Desktop systems, small NAS, containers with 4-8GB RAM");
        println!("   ✅ Use when: Large media libraries (100K-500K files), high performance");
        println!("   ⚙️  Environment variables:");
        println!("      ZEROCOPY_CACHE_MB=32");
        println!("      ZEROCOPY_INDEX_SIZE=6000000");
        println!("      ZEROCOPY_BATCH_SIZE=300000");
        println!("      ZEROCOPY_ENABLE_WAL=true");
        println!("      ZEROCOPY_SYNC_FREQUENCY_SECS=15");
        println!();
        
        println!("🚀 LARGE (64MB cache, 8M index, 500K batch):");
        println!("   ✅ Best for: High-end servers, dedicated media servers, 8-16GB RAM");
        println!("   ✅ Use when: Massive media libraries (500K-1M files), maximum performance");
        println!("   ⚙️  Environment variables:");
        println!("      ZEROCOPY_CACHE_MB=64");
        println!("      ZEROCOPY_INDEX_SIZE=8000000");
        println!("      ZEROCOPY_BATCH_SIZE=500000");
        println!("      ZEROCOPY_ENABLE_WAL=true");
        println!("      ZEROCOPY_SYNC_FREQUENCY_SECS=10");
        println!();
        
        println!("⚡ EXTREME (512MB cache, 10M index, 1M batch):");
        println!("   ✅ Best for: Enterprise servers, cloud instances, 32GB+ RAM");
        println!("   ✅ Use when: Enormous media libraries (1M+ files), absolute maximum performance");
        println!("   ⚙️  Environment variables:");
        println!("      ZEROCOPY_CACHE_MB=512");
        println!("      ZEROCOPY_INDEX_SIZE=10000000");
        println!("      ZEROCOPY_BATCH_SIZE=1000000");
        println!("      ZEROCOPY_ENABLE_WAL=true");
        println!("      ZEROCOPY_SYNC_FREQUENCY_SECS=5");
        println!();
        
        println!("⚡ PERFORMANCE TIPS:");
        println!("   • Start with MINIMAL and scale up based on actual performance needs");
        println!("   • Monitor memory usage: ZeroCopy cache + index should be <25% of total RAM");
        println!("   • Enable WAL for better write performance on larger configurations");
        println!("   • Larger batch sizes help with bulk operations but use more memory");
        println!("   • SSD storage significantly improves performance for all configurations");
        println!();
        
        println!("🔧 CUSTOM CONFIGURATION:");
        println!("   You can mix and match settings based on your specific needs.");
        println!("   See the full list of environment variables in the documentation.");
    }
}

#[tokio::test]
#[ignore] // Excluded from regular test runs - run manually with: cargo test test_database_performance_comparison --test database_performance_comparison -- --ignored
async fn test_database_performance_comparison() -> Result<()> {
    println!("🔬 Initializing comprehensive database performance comparison...");
    println!("This test compares SQLite vs ZeroCopy across multiple configurations.");
    println!("Expected runtime: 30-60 seconds depending on system performance.");
    println!();
    
    let comparison = DatabasePerformanceComparison::new().await?;
    comparison.run_comprehensive_benchmark().await?;
    
    Ok(())
}

#[tokio::test]
#[ignore] // Excluded from regular test runs
async fn test_bulk_insert_performance() -> Result<()> {
    let comparison = DatabasePerformanceComparison::new().await?;
    let profile = ZeroCopyProfile::minimal();
    let (sql_metrics, zerocopy_metrics) = comparison.test_bulk_insert_with_profile(&profile).await?;
    
    println!("SQL Bulk Insert: {:.2} ops/sec", sql_metrics.throughput_ops_per_sec);
    println!("ZeroCopy Bulk Insert: {:.2} ops/sec", zerocopy_metrics.throughput_ops_per_sec);
    
    // Assert that both operations completed successfully
    assert!(sql_metrics.files_processed > 0);
    assert!(zerocopy_metrics.files_processed > 0);
    
    Ok(())
}

#[tokio::test]
#[ignore] // Excluded from regular test runs
async fn test_query_performance() -> Result<()> {
    let comparison = DatabasePerformanceComparison::new().await?;
    let profile = ZeroCopyProfile::minimal();
    
    // Create and populate a ZeroCopy database for testing
    let zerocopy_db = comparison.create_zerocopy_db(&profile).await?;
    let _ = zerocopy_db.bulk_store_media_files(&comparison.test_files).await?;
    
    // Test query performance (simplified version)
    let start_time = Instant::now();
    for i in 0..100 {
        let artist = format!("Artist {}", i % 100);
        let _ = zerocopy_db.get_music_by_artist(&artist).await?;
    }
    let duration = start_time.elapsed();
    let throughput = 100.0 / duration.as_secs_f64();
    
    println!("ZeroCopy Query Performance: {:.2} queries/sec", throughput);
    assert!(throughput > 0.0);
    
    Ok(())
}

#[tokio::test]
#[ignore] // Excluded from regular test runs
async fn test_concurrent_access_performance() -> Result<()> {
    let comparison = DatabasePerformanceComparison::new().await?;
    let profile = ZeroCopyProfile::medium(); // Use medium config for concurrent testing
    
    // Create and populate a ZeroCopy database for testing
    let zerocopy_db = comparison.create_zerocopy_db(&profile).await?;
    let _ = zerocopy_db.bulk_store_media_files(&comparison.test_files).await?;
    
    // Test concurrent access (simplified version)
    let concurrent_tasks = 5;
    let operations_per_task = 20;
    
    let start_time = Instant::now();
    let mut handles = Vec::new();
    
    for task_id in 0..concurrent_tasks {
        let db = Arc::clone(&zerocopy_db);
        let handle = tokio::spawn(async move {
            for i in 0..operations_per_task {
                let artist = format!("Artist {}", (task_id * operations_per_task + i) % 100);
                let _ = db.get_music_by_artist(&artist).await;
            }
        });
        handles.push(handle);
    }
    
    // Wait for all tasks to complete
    for handle in handles {
        handle.await.unwrap();
    }
    
    let duration = start_time.elapsed();
    let total_ops = concurrent_tasks * operations_per_task;
    let throughput = total_ops as f64 / duration.as_secs_f64();
    
    println!("ZeroCopy Concurrent Access: {:.2} ops/sec", throughput);
    assert!(throughput > 0.0);
    
    Ok(())
}

/// Benchmark different ZeroCopy configurations - Quick test for all profiles
#[tokio::test]
#[ignore] // Excluded from regular test runs
async fn test_zerocopy_configurations() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let test_files = DatabasePerformanceComparison::generate_test_media_files(2000);
    
    let profiles = vec![
        ZeroCopyProfile::minimal(),
        ZeroCopyProfile::small(),
        ZeroCopyProfile::medium(),
        ZeroCopyProfile::large(),
    ];
    
    println!("🔬 Testing ZeroCopy configuration scaling...");
    println!("Test dataset: {} files", test_files.len());
    println!("{}", "-".repeat(60));
    
    for profile in &profiles {
        let db_path = temp_dir.path().join(format!("zerocopy_{}.db", profile.name.replace(" ", "_").replace("(", "").replace(")", "").replace(",", "")));
        let db = ZeroCopyDatabase::new(db_path, Some(profile.config.clone())).await?;
        db.initialize().await?;
        db.open().await?;
        
        let start_time = Instant::now();
        let _ids = db.bulk_store_media_files(&test_files).await?;
        let duration = start_time.elapsed();
        let throughput = test_files.len() as f64 / duration.as_secs_f64();
        
        println!("{}: {:.0} files/sec ({:.2}ms)", 
                 profile.name, throughput, duration.as_millis());
    }
    
    println!("\n💡 Run the full comparison with:");
    println!("   cargo test test_database_performance_comparison --test database_performance_comparison -- --ignored --nocapture");
    
    Ok(())
}

/// Test to verify ZeroCopy is using minimal default settings
#[tokio::test]
async fn test_zerocopy_minimal_defaults() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let db_path = temp_dir.path().join("test_minimal.db");
    
    // Create database with default configuration
    let db = ZeroCopyDatabase::new(db_path, None).await?;
    db.initialize().await?;
    db.open().await?;
    
    // Get the configuration to verify minimal settings
    let config = db.get_config().await;
    
    println!("🔍 ZeroCopy Minimal Default Configuration:");
    println!("   Memory cache: {}MB", config.memory_map_size_mb);
    println!("   Index cache: {} entries", config.index_cache_size);
    println!("   Batch size: {} files", config.batch_size);
    println!("   Initial file size: {}MB", config.initial_file_size_mb);
    println!("   Max file size: {}GB", config.max_file_size_gb);
    println!("   Sync frequency: {}s", config.sync_frequency.as_secs());
    println!("   WAL enabled: {}", config.enable_wal);
    println!("   Compression enabled: {}", config.enable_compression);
    
    // Verify minimal settings
    assert_eq!(config.memory_map_size_mb, 1, "Memory cache should be 1MB");
    assert_eq!(config.index_cache_size, 1000, "Index cache should be 1000 entries");
    assert_eq!(config.batch_size, 100, "Batch size should be 100 files");
    assert_eq!(config.initial_file_size_mb, 1, "Initial file size should be 1MB");
    assert_eq!(config.max_file_size_gb, 1, "Max file size should be 1GB");
    assert_eq!(config.sync_frequency.as_secs(), 60, "Sync frequency should be 60s");
    assert!(!config.enable_wal, "WAL should be disabled by default");
    assert!(!config.enable_compression, "Compression should be disabled by default");
    
    println!("✅ All minimal default settings verified!");
    
    Ok(())
}